{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7NdyPvasOVEbRylgg7TYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donggale72/10000.html/blob/main/5_2_%EC%BC%80%EB%9D%BC%EC%8A%A4_%EC%B0%BD%EC%8B%9C%EC%9E%90%EC%97%90%EA%B2%8C_%EB%B0%B0%EC%9A%B0%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9DImageDataGenerator%EC%97%B0%EC%8A%B5_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQle8nfXmvJy",
        "outputId": "39497558-e0f7-41ef-ef83-3166b7c6a625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SkillTreePython-DeepLearning'...\n",
            "remote: Enumerating objects: 1007, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 1007 (delta 65), reused 55 (delta 30), pack-reused 906\u001b[K\n",
            "Receiving objects: 100% (1007/1007), 56.03 MiB | 25.94 MiB/s, done.\n",
            "Resolving deltas: 100% (544/544), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yebiny/SkillTreePython-DeepLearning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/SkillTreePython-DeepLearning/02.케라스_창시자에게_배우는_딥러닝/scripts')\n",
        "from import_lib import *"
      ],
      "metadata": {
        "id": "q14PM-WDnq4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gilbutITbook/006975"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ8yA7_knq0-",
        "outputId": "b1788b24-1d68-4db8-facb-3c41b7f70219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '006975'...\n",
            "remote: Enumerating objects: 102534, done.\u001b[K\n",
            "remote: Total 102534 (delta 0), reused 0 (delta 0), pack-reused 102534\u001b[K\n",
            "Receiving objects: 100% (102534/102534), 202.75 MiB | 23.82 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Checking out files: 100% (104042/104042), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "org_img_paths=sorted(glob.glob('/content/006975/datasets/cats_and_dogs/train/*jpg'))\n",
        "len(org_img_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9GBJWbBnqv-",
        "outputId": "85200ec9-2a28-4312-a457-d747f1aa0aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('new_ds')"
      ],
      "metadata": {
        "id": "sf7wvfNVqLsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dir_type in ['train', 'valid', 'test']:\n",
        "  dir_path=f'new_ds/{dir_type}'\n",
        "  os.mkdir(dir_path)\n",
        "  print(f'*{dir_path} is made')\n",
        "  for dir_label in ['cat', 'dog']:\n",
        "    dir_path=f'new_ds/{dir_type}/{dir_label}'\n",
        "    os.mkdir(dir_path)\n",
        "    print(f'*ㄴ{dir_path}is made')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYonQnmanqtI",
        "outputId": "3923b566-5b94-4623-b391-a18f45fa95f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*new_ds/train is made\n",
            "*ㄴnew_ds/train/catis made\n",
            "*ㄴnew_ds/train/dogis made\n",
            "*new_ds/valid is made\n",
            "*ㄴnew_ds/valid/catis made\n",
            "*ㄴnew_ds/valid/dogis made\n",
            "*new_ds/test is made\n",
            "*ㄴnew_ds/test/catis made\n",
            "*ㄴnew_ds/test/dogis made\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "for img_path in org_img_paths:\n",
        "  info=img_path.split('/')[-1]\n",
        "  label, idx, _=info.split('.')\n",
        "\n",
        "  if 0<=int(idx)<1000: target_path=f'/content/new_ds/train/{label}/{info}'\n",
        "  elif 1000<=int(idx)<1500: target_path=f'/content/new_ds/valid/{label}/{info}'\n",
        "  else: target_path=f'/content/new_ds/test/{label}/{info}'\n",
        "  shutil.copyfile(img_path, target_path)"
      ],
      "metadata": {
        "id": "DhrguFaPnqrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dir_type in ['train', 'valid', 'test']:\n",
        "  dir_path=f'new_ds/{dir_type}'\n",
        "  for dir_label in ['cat', 'dog']:\n",
        "    dir_path=f'new_ds/{dir_type}/{dir_label}'\n",
        "    n_imgs=len(os.listdir(dir_path))\n",
        "    print(f'*{dir_path} 이미지 전체 개수: {n_imgs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzgerSycnqn-",
        "outputId": "ea507fa5-ca28-4d86-ab9a-37e0fdcd1f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*new_ds/train/cat 이미지 전체 개수: 1000\n",
            "*new_ds/train/dog 이미지 전체 개수: 1000\n",
            "*new_ds/valid/cat 이미지 전체 개수: 500\n",
            "*new_ds/valid/dog 이미지 전체 개수: 500\n",
            "*new_ds/test/cat 이미지 전체 개수: 500\n",
            "*new_ds/test/dog 이미지 전체 개수: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  x = layers.Input(shape=(150,150, 3)) # resolution 축소 및 크기를 동일하게 맞춰주는 작업 필요\n",
        "  y = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Conv2D(64, 3, activation='relu')(y)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Conv2D(128, 3, activation='relu')(y)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Conv2D(128, 3, activation='relu')(y)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Flatten()(y)\n",
        "  y = layers.Dense(512, activation='relu')(y)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(y)\n",
        "  return models.Model(x, y)"
      ],
      "metadata": {
        "id": "qVpFg618nqlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmS4kfh1nqiu",
        "outputId": "f08cefbe-5365-45a1-9a1f-a486b5d9f7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import losses, optimizers\n",
        "model.compile(loss=losses.BinaryCrossentropy(),\n",
        "              optimizer=optimizers.RMSprop(learning_rate=0.0001),\n",
        "              metrics=['acc'])\n"
      ],
      "metadata": {
        "id": "kPmx9RdNnqf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_gen=ImageDataGenerator(rescale=1.0/255.0).flow_from_directory('/content/new_ds/train',\n",
        "                                                                    target_size=(150,150),\n",
        "                                                                    batch_size=20,\n",
        "                                                                    class_mode='binary')\n",
        "valid_gen=ImageDataGenerator(rescale=1.0/255.0).flow_from_directory('/content/new_ds/valid',\n",
        "                                                                    target_size=(150,150),\n",
        "                                                                    batch_size=20,\n",
        "                                                                    class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgFr4I5inqd3",
        "outputId": "357e4f66-aee2-479e-ec3b-cdb32a9593bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (x_batch, y_batch) in train_gen:\n",
        "  print(f'배치 X 크기: {x_batch.shape}')\n",
        "  print(f'배치 Y 크기: {y_batch.shape}')\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1rShs7inqa4",
        "outputId": "a918ccb7-7432-4843-f132-69385f945216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "배치 X 크기: (20, 150, 150, 3)\n",
            "배치 Y 크기: (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_gen, \n",
        "                  steps_per_epoch=100,\n",
        "                  epochs=30,\n",
        "                  validation_data=valid_gen,\n",
        "                  validation_steps=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us3hktQBnqYg",
        "outputId": "aee50dee-6949-411b-b545-6cbbdcdc45cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 29s 122ms/step - loss: 0.6923 - acc: 0.5315 - val_loss: 0.7049 - val_acc: 0.5000\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6616 - acc: 0.5965 - val_loss: 0.6415 - val_acc: 0.6340\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6067 - acc: 0.6755 - val_loss: 0.6090 - val_acc: 0.6670\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5757 - acc: 0.7040 - val_loss: 0.6292 - val_acc: 0.6470\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5455 - acc: 0.7215 - val_loss: 0.5978 - val_acc: 0.6810\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5184 - acc: 0.7470 - val_loss: 0.5747 - val_acc: 0.7060\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4863 - acc: 0.7650 - val_loss: 0.5475 - val_acc: 0.7260\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4588 - acc: 0.7895 - val_loss: 0.5815 - val_acc: 0.6950\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4344 - acc: 0.7975 - val_loss: 0.6622 - val_acc: 0.6590\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.4041 - acc: 0.8170 - val_loss: 0.5364 - val_acc: 0.7200\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3773 - acc: 0.8285 - val_loss: 0.5632 - val_acc: 0.7300\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3479 - acc: 0.8530 - val_loss: 0.5828 - val_acc: 0.7220\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3271 - acc: 0.8600 - val_loss: 0.5629 - val_acc: 0.7270\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.3031 - acc: 0.8730 - val_loss: 0.8181 - val_acc: 0.6690\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2833 - acc: 0.8815 - val_loss: 0.5756 - val_acc: 0.7350\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2478 - acc: 0.9045 - val_loss: 0.6157 - val_acc: 0.7340\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2272 - acc: 0.9120 - val_loss: 0.6567 - val_acc: 0.7170\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2145 - acc: 0.9235 - val_loss: 0.6994 - val_acc: 0.7230\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1969 - acc: 0.9215 - val_loss: 0.6106 - val_acc: 0.7380\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1738 - acc: 0.9380 - val_loss: 0.6788 - val_acc: 0.7330\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1560 - acc: 0.9425 - val_loss: 0.7654 - val_acc: 0.7130\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1404 - acc: 0.9505 - val_loss: 0.6789 - val_acc: 0.7420\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.1136 - acc: 0.9615 - val_loss: 0.7046 - val_acc: 0.7430\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1003 - acc: 0.9680 - val_loss: 0.7337 - val_acc: 0.7470\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.0944 - acc: 0.9690 - val_loss: 0.7390 - val_acc: 0.7360\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0780 - acc: 0.9790 - val_loss: 0.8715 - val_acc: 0.7380\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0660 - acc: 0.9830 - val_loss: 0.8020 - val_acc: 0.7360\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.0610 - acc: 0.9840 - val_loss: 0.8176 - val_acc: 0.7400\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.0540 - acc: 0.9815 - val_loss: 0.8716 - val_acc: 0.7310\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.0382 - acc: 0.9925 - val_loss: 1.6458 - val_acc: 0.6650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "id": "ssO-9S07nqV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plot_result import *\n",
        "plot_lcurve([history], [''], ['dodgerblue'], x_itv=5)\n"
      ],
      "metadata": {
        "id": "oSjgoNoAnqSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_gen= ImageDataGenerator(rescale=1.0/255.0,\n",
        "                            rotation_range=40,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            shear_range=0.2,\n",
        "                            zoom_range=0.2,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode='nearest',\n",
        "                            brightness_range=[0.7,1.3]\n",
        "                            )"
      ],
      "metadata": {
        "id": "C4GN9NNUAInY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img=image.load_img(org_img_paths[4], target_size=(150,150))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x, 0)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "MvYTPMSmnqM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, x_aug in enumerate(aug_gen.flow(x, batch_size=1)):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(x_aug[0])\n",
        "  plt.xticks([]); plt.yticks([])\n",
        "  if i==5: break"
      ],
      "metadata": {
        "id": "-ZiNx2cunqKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model2():\n",
        "  x = layers.Input(shape=(150,150, 3)) # resolution 축소 및 크기를 동일하게 맞춰주는 작업 필요\n",
        "  y = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Conv2D(64, 3, activation='relu')(y)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Conv2D(128, 3, activation='relu')(y)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Conv2D(128, 3, activation='relu')(y)\n",
        "  y = layers.MaxPool2D()(y)\n",
        "  y = layers.Flatten()(y)\n",
        "  y = layers.Dense(512, activation='relu')(y)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(y)\n",
        "  return models.Model(x, y, name='model2')\n",
        "\n",
        "model2=create_model2()\n",
        "model2.summary()\n",
        "\n",
        "from tensorflow.keras import losses, optimizers\n",
        "model2.compile(loss=losses.BinaryCrossentropy(),\n",
        "               optimizer=optimizers.RMSprop(learning_rate=0.0001),\n",
        "               metrics=['acc'])"
      ],
      "metadata": {
        "id": "nMLf6F2lnqFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen=aug_gen.flow_from_directory('/content/new_ds/train',\n",
        "                                      target_size=(150,150),\n",
        "                                      batch_size=20,\n",
        "                                      class_mode='binary')\n",
        "valid_gen=ImageDataGenerator(rescale=1.0/255.0).flow_from_directory('/content/new_ds/valid',\n",
        "                                                                    target_size=(150,150),\n",
        "                                                                    batch_size=20,\n",
        "                                                                    class_mode='binary')\n",
        "\n",
        "history2=model2.fit(train_gen, \n",
        "                    steps_per_epoch=100,\n",
        "                    epochs=50,\n",
        "                    validation_data= valid_gen,\n",
        "                    validation_steps=50)"
      ],
      "metadata": {
        "id": "bJbJTHhEnqCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save('cats_and_dogs_small.h5')"
      ],
      "metadata": {
        "id": "JJpwTMzRnqAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lcurve([history2],[''],['dodgerblue'])"
      ],
      "metadata": {
        "id": "rlQu1-REnp9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/images/classification?hl=ko"
      ],
      "metadata": {
        "id": "9ORe106JD6Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, utils\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "ljgqrZjEnp4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "dataset_url='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "data_dir=tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir=pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "k9SyJ8N8np1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count=len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n"
      ],
      "metadata": {
        "id": "4jfd5oMinpyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roses=list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "metadata": {
        "id": "LmXH7CqhnpwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(roses[1]))"
      ],
      "metadata": {
        "id": "sMWR19XMnptW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tulips = list(data_dir.glob('tulips/*'))\n",
        "PIL.Image.open(str(tulips[0]))"
      ],
      "metadata": {
        "id": "X1iqY7xQJQct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(tulips[1]))"
      ],
      "metadata": {
        "id": "V-tI7jvWJQUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "img_height=180\n",
        "img_width=180\n"
      ],
      "metadata": {
        "id": "nsuKyuWEnppm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "p9TnXv3gHAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir, \n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "W3xVrP9NLl6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "4MOOAKX4HAJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax=plt.subplot(3,3, i+1)\n",
        "    plt.imshow(images[i].numpy().astype('uint8'))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "wZoeb8bZHAD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "9bpLp_v1HAA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "4tN0jjgLG_9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer=layers.experimental.preprocessing.Rescaling(1./255.)"
      ],
      "metadata": {
        "id": "suZadWw_G_6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds=train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch=next(iter(normalized_ds))\n",
        "first_image=image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "mKFWLkGkG_3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=5\n",
        "\n",
        "model=Sequential([\n",
        "                  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "                  layers.Conv2D(16,3, padding='same',activation='relu'),\n",
        "                  layers.MaxPooling2D(),\n",
        "                  layers.Conv2D(32,3, padding='same', activation='relu'),\n",
        "                  layers.MaxPooling2D(),\n",
        "                  layers.Conv2D(64,3, padding='same', activation='relu'),\n",
        "                  layers.MaxPooling2D(),\n",
        "                  layers.Flatten(),\n",
        "                  layers.Dense(128, activation='relu'),\n",
        "                  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "EEmSz6_9G_0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ye_8q6EYG_xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "jd5eWf-yoW66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range=range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yWeuypopG_re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmentation=keras.Sequential(\n",
        "    [\n",
        "    layers.experimental.preprocessing.RandomFlip('horizontal',\n",
        "                                                input_shape=(img_height,\n",
        "                                                             img_width,\n",
        "                                                             3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1) ]\n",
        ")"
      ],
      "metadata": {
        "id": "EbCRL6NFG_n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images=data_augmentation(images)\n",
        "    ax=plt.subplot(3,3,i+1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype('uint8'))\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "7GuP3pdvG_iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential([\n",
        "                  data_augmentation,\n",
        "                  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "                  layers.Conv2D(16,3, padding='same',activation='relu'),\n",
        "                  layers.MaxPooling2D(),\n",
        "                  layers.Conv2D(32,3, padding='same', activation='relu'),\n",
        "                  layers.MaxPooling2D(),\n",
        "                  layers.Conv2D(64,3, padding='same', activation='relu'),\n",
        "                  layers.MaxPooling2D(),\n",
        "                  layers.Dropout(0.2),\n",
        "                  layers.Flatten(),\n",
        "                  layers.Dense(128, activation='relu'),\n",
        "                  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "x6ib7k6mG_e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bnLJJTabG_b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "C2tzBQm-atmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=15\n",
        "history=model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "1YnFSG8zati_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range=range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, acc, label='Training Loss')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "u-fVvR8Iatc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url='https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg'\n",
        "sunflower_path=tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img=keras.preprocessing.image.load_img(\n",
        "    sunflower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array=keras.preprocessing.image.img_to_array(img)\n",
        "img_array=tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions=model.predict(img_array)\n",
        "score=tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    'This image most likely belongs to {} with a{:.2f} percent confidence.'.format(class_names[np.argmax(score)], 100*np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "m_BJNldnataP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbIp0PZHatXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2KMIvCcatU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jaKGIEeSatR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbE3HQEfatMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eGaJwILqatH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBUWn9RratE3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}